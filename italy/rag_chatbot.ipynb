{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IVZTYMYqhEyD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from langchain.prompts import (\n",
    "    PromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    ChatPromptTemplate,)\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain_community.document_loaders.dataframe import DataFrameLoader\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain.embeddings import CacheBackedEmbeddings\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "\n",
    "try:\n",
    "    from google.colab.userdata import get as getenv\n",
    "    print(\"Running in colab\")\n",
    "except ImportError:\n",
    "    from os import getenv\n",
    "    import dotenv\n",
    "    dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = getenv('OPENAI_API_KEY')\n",
    "assert OPENAI_API_KEY, \"An API key for OpenAI is required to be set as <OPENAI_API_KEY>.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up LangSmith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "LANGCHAIN_API_KEY = getenv('LANGCHAIN_API_KEY')\n",
    "LANGCHAIN_ENDPOINT = getenv('LANGCHAIN_ENDPOINT')\n",
    "assert LANGCHAIN_API_KEY, \"An API key for LangChainSmith is required to be set as <LANGCHAIN_API_KEY>.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1rzeDBNMoijW"
   },
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TeXyY2YLWqcD"
   },
   "outputs": [],
   "source": [
    "# Dataset files\n",
    "DATASET_PATH = \"Amap-results_NJU-Gulou-3000m.csv\"\n",
    "\n",
    "LLM_MODEL_NAME = \"gpt-4\"\n",
    "EMBEDDING_MODEL_NAME = \"text-embedding-ada-002\"\n",
    "\n",
    "# Embeddings\n",
    "EMBEDDINGS_CACHE_STORE=\"./cache/\"\n",
    "\n",
    "# Faiss\n",
    "FAISS_REVIEWS_PATH_COSINE = \"faiss_index_cosine\"\n",
    "FAISS_INDEX_NAME = \"index\"\n",
    "FAISS_DISTANCE_STRATEGY_COSINE = \"COSINE_DISTANCE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eUr5hUrPoijY"
   },
   "source": [
    "## Load Dataset\n",
    "\n",
    "Here we are using 2 csv files containing places (restuarants, bars, ...) info and reviews for each of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aONHvzXAoijZ"
   },
   "outputs": [],
   "source": [
    "def get_documents(content_func=lambda row:row['name'] + '\\n' + row['tag'],\n",
    "                  source_func=lambda row:row['address'],\n",
    "                  metadata_fields=[]):\n",
    "\n",
    "  # Load the dataset\n",
    "  dataset_df = pd.read_csv(DATASET_PATH)\n",
    "  dataset_df.drop_duplicates(inplace=True)\n",
    "\n",
    "  # Add page_content and source columns using their corresponding functions\n",
    "  dataset_df['page_content'] = dataset_df.apply(content_func, axis=1)\n",
    "  dataset_df['source'] = dataset_df.apply(source_func, axis=1)\n",
    "\n",
    "  # Update metadata_fields with 'page_content', 'source'\n",
    "  metadata_fields = list(set(metadata_fields + ['page_content', 'source']))\n",
    "\n",
    "  loader = DataFrameLoader(dataset_df[metadata_fields], page_content_column='page_content')\n",
    "  return loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E5jUkJ8XoijZ"
   },
   "outputs": [],
   "source": [
    "def content_func(row) -> str:\n",
    "  content_fields = [\"name\",\n",
    "                    \"address\",\n",
    "                    \"type\",\n",
    "                    \"tag\",\n",
    "                    \"cost\",\n",
    "                    \"rating\",\n",
    "                    \"opentime_today\",\n",
    "                    \"tel\"]\n",
    "  return '\\n'.join(f\"{key}={row[key]}\" for key in content_fields if pd.notna(row[key]))\n",
    "\n",
    "metadata_fields = [\"location\", \"opentime_week\"]\n",
    "\n",
    "documents = get_documents(content_func, metadata_fields=metadata_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WH4HR9emoijZ",
    "outputId": "fa47e9ba-3bdf-4c36-c553-300479119540"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "## Take a look at a sample document\n",
    "print(documents[0].page_content)\n",
    "print(documents[0].metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wLU4f9yqoija"
   },
   "source": [
    "## Load Embeddings model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = OpenAIEmbeddings(model=EMBEDDING_MODEL_NAME, openai_api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = embedding_model.embed_query(\"One sample query!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import numpy as np\n",
    "array = np.array(result)\n",
    "print(f\"embedding shape: {array.shape}\\nembedding norm: {np.linalg.norm(array, ord=2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yZU69PxDoijg"
   },
   "source": [
    "## Create FAISS (Vector Database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "ClgYJkU5oijj"
   },
   "outputs": [],
   "source": [
    "def get_vector_database(documents, embedding_model, distance_strategy):\n",
    "\n",
    "  vector_database = FAISS.from_documents(\n",
    "      documents, embedding_model,\n",
    "      distance_strategy= distance_strategy\n",
    "      )\n",
    "  return vector_database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "doclen = len(documents)\n",
    "for batch in range(doclen//100 + 1):\n",
    "    docs = documents[batch*100:(batch+1)*100]\n",
    "    if batch ==0:\n",
    "        vector_db = get_vector_database(docs, embedding_model, FAISS_DISTANCE_STRATEGY_COSINE)\n",
    "    else:\n",
    "\n",
    "        vector_db.merge_from(get_vector_database(docs, embedding_model, FAISS_DISTANCE_STRATEGY_COSINE))\n",
    "    time.sleep(10) # Sleep for 10 seconds to avoid hitting rate limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_db.save_local(folder_path=FAISS_REVIEWS_PATH_COSINE, index_name=FAISS_INDEX_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_db = FAISS.load_local(folder_path=FAISS_REVIEWS_PATH_EUCLIDEAN,\n",
    "                             embeddings=embedding_model,\n",
    "                             index_name=FAISS_INDEX_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "docs = vector_db.similarity_search(\"Give me information about some of the best pizza restaurant in the city?\", k = 5)\n",
    "for doc in docs:\n",
    "    print(doc, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "question = \"where is the Enoteca Barcollo located? and what is its phone number?\"\n",
    "\n",
    "docs = vector_db.similarity_search(question, k = 5)\n",
    "\n",
    "for i in range(5):\n",
    "  print(docs[i], end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain.embeddings import CacheBackedEmbeddings\n",
    "from os import getenv\n",
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "\n",
    "# Faiss\n",
    "FAISS_REVIEWS_PATH_EUCLIDEAN = \"faiss_index_euclidean\"\n",
    "FAISS_INDEX_NAME = \"index\"\n",
    "FAISS_DISTANCE_STRATEGY='EUCLIDEAN_DISTANCE'\n",
    "EMBEDDING_MODEL_NAME = \"models/text-embedding-004\"\n",
    "EMBEDDINGS_CACHE_STORE=\"./cache/\"\n",
    "\n",
    "GOOGLE_API_KEY = getenv('GOOGLE_API_KEY')\n",
    "\n",
    "embedding_model = GoogleGenerativeAIEmbeddings(model=EMBEDDING_MODEL_NAME)\n",
    "store = LocalFileStore(EMBEDDINGS_CACHE_STORE)\n",
    "embedding_model = CacheBackedEmbeddings.from_bytes_store(embedding_model, store)\n",
    "\n",
    "vector_db = FAISS.load_local(folder_path=FAISS_REVIEWS_PATH_EUCLIDEAN,\n",
    "                             embeddings=embedding_model,\n",
    "                             index_name=FAISS_INDEX_NAME,\n",
    "                             allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rk1-sq8Voijw"
   },
   "source": [
    "## Load LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=LLM_MODEL_NAME, openai_api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "llm.invoke(\"Hi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d4SU2uzJoijz"
   },
   "source": [
    "## Create LangChain pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import (\n",
    "    PromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    ChatPromptTemplate,)\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.schema.runnable import RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "GNPL6u4EkAW3"
   },
   "outputs": [],
   "source": [
    "review_template_str = \"\"\"\n",
    "Your job is to use Google Map restaurants and bars reviews to help people find best places to go for a meal or a drink.\n",
    "Use the following information and reviews to answer the questions. if the context is not about restaurants,\n",
    "then kindly tell the user that you can only provide assistance and answer questions related to restaurants.\n",
    "If you don't know an answer based on the context, say you don't know. Answer context:\n",
    "{context}\n",
    "\"\"\"\n",
    "\n",
    "system_prompt = SystemMessagePromptTemplate(\n",
    "    prompt=PromptTemplate(\n",
    "        input_variables=[\"context\"], template=review_template_str\n",
    "    )\n",
    ")\n",
    "\n",
    "human_prompt = HumanMessagePromptTemplate(\n",
    "    prompt=PromptTemplate(input_variables=[\"question\"], template=\"{question}\")\n",
    ")\n",
    "messages = [system_prompt, human_prompt]\n",
    "\n",
    "review_prompt_template = ChatPromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"], messages=messages\n",
    ")\n",
    "\n",
    "reviews_retriever = vector_db.as_retriever(search_kwargs={'k': 20,})\n",
    "\n",
    "review_chain = (\n",
    "    {\"context\": reviews_retriever, \"question\": RunnablePassthrough()}\n",
    "    | review_prompt_template\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "question = \"\"\"Where can I find delicious pizzas?\"\"\"\n",
    "print(review_chain.invoke(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "32GruWzvuWnM",
    "outputId": "b53bc31b-0755-4fe6-99ce-5539fccb8b05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "question = \"\"\"Where can I find delicious pizzas?\"\"\"\n",
    "print(review_chain.invoke(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LzzRDTT6tTrt",
    "outputId": "2ea12f61-646e-45fb-839c-595749536e43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "question = \"\"\"What are the pros and cons of Napoli Centrale?\"\"\"\n",
    "print(review_chain.invoke(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "question = \"\"\"Give the name, address and phone number of some good steak houses for a romantic dinner.\"\"\"\n",
    "print(review_chain.invoke(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "question = \"\"\"Give the name, address and phone number of the best steak houses with a 50 euro budget?\"\"\"\n",
    "\n",
    "print(review_chain.invoke(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "question = \"\"\"Give the name, address and phone number of the some good sandwich places?\"\"\"\n",
    "print(review_chain.invoke(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "question = \"\"\"What are the most affordable but high-quality restaurants in City?\"\"\"\n",
    "result = review_chain.invoke(question)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "question = \"\"\"How can I make a roast beef sandwich at home?\"\"\"\n",
    "print(review_chain.invoke(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "question = \"\"\"What is RAG?\"\"\"\n",
    "print(review_chain.invoke(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "question = \"\"\"What is Natural Language Processing?\"\"\"\n",
    "print(review_chain.invoke(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "question = \"\"\"Explain Natural Language Processing.\"\"\"\n",
    "print(review_chain.invoke(question))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation on Synthetic Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_question_answer_pairs(documents, generator_llm, num_pairs=30):\n",
    "  question_answer_pairs = []\n",
    "  for _ in range(num_pairs):\n",
    "    document = random.choice(documents)\n",
    "    page_content = document.page_content\n",
    "    prompt = f\"This is a factual text passage: {page_content}. Write only one question about the restaurant based on the provided text passage. only write the quesion and noting else.\"\n",
    "\n",
    "    question = generator_llm.invoke(prompt).content\n",
    "    answer = generator_llm.invoke(f\"From the following passage, answer the question: {question}\\n{page_content}\").content\n",
    "    question_answer_pairs.append({\"question\": question, \"answer\": answer, \"document\": document})\n",
    "\n",
    "  return question_answer_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_llm = ChatGoogleGenerativeAI(model=LLM_MODEL_NAME)\n",
    "question_answer_pairs = get_question_answer_pairs(documents, generator_llm, num_pairs=30)\n",
    "df = pd.DataFrame(question_answer_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_answers = []\n",
    "for question in df[\"question\"]:\n",
    "    question = question.split(\"\\n\")[0]\n",
    "    answer = review_chain.invoke(question)\n",
    "    rag_answers.append(answer)\n",
    "\n",
    "df[\"rag_answer\"] = rag_answers\n",
    "df.to_csv('question_answer_pairs.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "df.to_csv('question_answer_pairs.csv', index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "df = pd.read_csv('question_answer_pairs.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "for i in range(10): \n",
    "    print(df[\"question\"].loc[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limitatoins of classic LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "question = \"Does Bar Fortuna Sas in Padova city offer delivery services?\"\n",
    "answer = llm.invoke(question).content\n",
    "pprint(question)\n",
    "pprint(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "question = \"Does Bar Fortuna Sas in Padova city offer delivery services?\"\n",
    "answer = review_chain.invoke(question)\n",
    "print(question)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "question = \"What kind of food is served at Veni Vidi Vino Enoteca?\"\n",
    "answer = llm.invoke(question).content\n",
    "pprint(question)\n",
    "pprint(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "question = \"What kind of food is served at Veni Vidi Vino Enoteca?\"\n",
    "answer = review_chain.invoke(question)\n",
    "pprint(question)\n",
    "pprint(answer)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ByteBites_ItalyRag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
