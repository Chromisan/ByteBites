{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 配置环境\n",
    "\n",
    "在运行之前需要安装所需的python包。建议使用anaconda创建一个新的虚拟环境，具体方法为打开Anaconda navigator，创建环境，环境名称可以命名为ByteBites。\n",
    "\n",
    "激活环境，确保在vscode的资源管理器中打开ByteBites文件夹。在vscode的左侧python扩展中，在global environments，选中刚才安装的环境，点击open in terminal，在打开的命令行中输入以下命令安装所需的包：\n",
    "```bash\n",
    "pip install -r italy/requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:15: SyntaxWarning: invalid escape sequence '\\A'\n",
      "<>:15: SyntaxWarning: invalid escape sequence '\\A'\n",
      "C:\\Users\\Chrom\\AppData\\Local\\Temp\\ipykernel_23772\\199738631.py:15: SyntaxWarning: invalid escape sequence '\\A'\n",
      "  DATASET_PATH = \"..\\Amap-results_NJU-Gulou-3000m.csv\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from langchain.prompts import (\n",
    "    PromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    ChatPromptTemplate,)\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain_community.document_loaders.dataframe import DataFrameLoader\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain.embeddings import CacheBackedEmbeddings\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "\n",
    "DATASET_PATH = \"..\\Amap-results_NJU-Gulou-3000m.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入CSV数据库\n",
    "\n",
    "以下代码从CSV文件导入餐厅数据，并生成一个新的文档对象documents。这个功能由DataFrameLoader提供。\n",
    "\n",
    "### 数据结构说明\n",
    "\n",
    "documents可以理解为一个list表格，每一行是包含两个字段的dict，两个字段分别为：  \n",
    "- `page_content`：值为字符串。将餐厅的所有信息整合在一个字符串中，用于喂给大模型。\n",
    "- `metadata`：值为dict。储存准备用于初过滤的硬性指标值，如经纬度、营业时间等。 \n",
    "\n",
    "### 示例\n",
    "\n",
    "假设原始csv文件如下：\n",
    "```csv\n",
    "name,address,location,type,tel,cost,rating,opentime_today,opentime_week,tag\n",
    "巴蜀鱼花(南大店),湖南路街道汉口路30号,\"118.779220,32.053685\",餐饮服务;中餐厅;火锅店,15380870767,,4.4,09:00-21:00,周一至周日 09:00-21:00,\n",
    "陕老顺肉夹馍,汉口路30号,\"118.779105,32.053716\",餐饮服务;餐饮相关场所;餐饮相关,15924140124,,4.4,10:00-21:00,周一至周日 10:00-21:00,肉夹馍\n",
    "```\n",
    "\n",
    "导入后的结果为：\n",
    "```python\n",
    "documents = [\n",
    "    ..., # 第一行略\n",
    "    {\n",
    "        \"page_content\": \"name=陕老顺肉夹馍\\naddress=汉口路30号\\nlocation=118.779105,32.053716\\ntype=餐饮服务;餐饮相关场所;餐饮相关\\ntag=肉夹馍\\nrating=4.4\\nopentime_today=10:00-21:00\\nopentime_week=周一至周日 10:00-21:00\\ntel=15924140124\",\n",
    "        \"metadata\": {\n",
    "            \"location\": \"118.779105,32.053716\",\n",
    "            \"opentime_week\": \"周一至周日 10:00-21:00\"\n",
    "        }\n",
    "    }\n",
    "]\n",
    "```\n",
    "\n",
    "### **注意**\n",
    "\n",
    "- 读取店铺数据的代码更改，导致csv文件中字段发生变化时：def content_func 中 python content_fields 的值要随之更改。\n",
    "- 想作为硬性指标的字段发生变化时：调用部分 metadata_fields 中的值要更改。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name=陕老顺肉夹馍\n",
      "address=汉口路30号\n",
      "location=118.779105,32.053716\n",
      "type=餐饮服务;餐饮相关场所;餐饮相关\n",
      "tag=肉夹馍\n",
      "rating=4.4\n",
      "opentime_today=10:00-21:00\n",
      "opentime_week=周一至周日 10:00-21:00\n",
      "tel=15924140124\n",
      "{'location': '118.779105,32.053716', 'opentime_week': '周一至周日 10:00-21:00'}\n"
     ]
    }
   ],
   "source": [
    "def get_documents(content_func=lambda row: row['name'] + '\\n' + row['tag'],  # 用于导入page_content的函数。如果调用时没传这个参数，默认是将每一行的name和tag拼接起来。\n",
    "                  # source_func=lambda row: row['address'],  # 后面没用到这个函数。用于导入source的函数。默认是将address作为文档来源。\n",
    "                  metadata_fields=[]):  # 导入metadata（一个dict）时打算加入进去的字段列表，默认为空。\n",
    "\n",
    "    # 加载数据库，读取指定路径的 CSV 文件\n",
    "    dataset_df = pd.read_csv(DATASET_PATH)\n",
    "    dataset_df.drop_duplicates(inplace=True) # 删除重复数据，确保数据唯一性\n",
    "\n",
    "    # 对原有数据分别用函数content_func和source_func处理，添加新的列 'page_content' 和'source'，这两列的值由两个函数得到\n",
    "    dataset_df['page_content'] = dataset_df.apply(content_func, axis=1)\n",
    "    # dataset_df['source'] = dataset_df.apply(source_func, axis=1)\n",
    "\n",
    "    # 将 'page_content' 字段添加到metadata_fields中\n",
    "    metadata_fields = list(set(metadata_fields + ['page_content']))\n",
    "\n",
    "    # 使用 DataFrameLoader 生成一个新文档对象。 'page_content'列作为文档内容，其他所有列都作为metadata的内容\n",
    "    loader = DataFrameLoader(dataset_df[metadata_fields], page_content_column='page_content')\n",
    "    return loader.load()\n",
    "\n",
    "def content_func(row) -> str: # 定义content_func函数，用于把每家店的所有信息拼到一起，返回成一个字符串。中间用换行符隔开。\n",
    "  content_fields = [\"name\",\n",
    "                    \"address\",\n",
    "                    # \"location\", \n",
    "                    \"type\",\n",
    "                    \"tag\",\n",
    "                    \"cost\",\n",
    "                    \"rating\",\n",
    "                    \"opentime_today\",\n",
    "                    \"opentime_week\", \n",
    "                    # \"tel\"\n",
    "                    ]\n",
    "  return '\\n'.join(f\"{key}={row[key]}\" for key in content_fields if pd.notna(row[key]))\n",
    "\n",
    "# 调用\n",
    "metadata_fields = [\"location\", \"opentime_week\"]\n",
    "documents = get_documents(content_func, metadata_fields=metadata_fields)\n",
    "\n",
    "# 展示\n",
    "print(documents[1].page_content)\n",
    "print(documents[1].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dotenv import load_dotenv\n",
    "# from langchain_openai import OpenAIEmbeddings\n",
    "# import os\n",
    "\n",
    "# #加载环境变量\n",
    "# load_dotenv()\n",
    "# #配置嵌入模型\n",
    "# EMBEDDING_MODEL_NAME = \"text-embedding-3-small\"  \n",
    "# embedding_model = OpenAIEmbeddings(\n",
    "#     model=EMBEDDING_MODEL_NAME,\n",
    "#     openai_api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 配置嵌入vecterbase所用的模型\n",
    "\n",
    "用的是huggingface上面的某个轻量级开源模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding shape: (384,)\n",
      "embedding norm: 1.0000000653766763\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# 初始化 HuggingFaceEmbeddings 模型\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",  # 轻量级模型\n",
    "    model_kwargs={\"device\": \"cpu\"},  # 如果电脑上安装了英伟达显卡，可改成 \"cuda\" 来加速\n",
    "    encode_kwargs={\"normalize_embeddings\": True})  # 归一化\n",
    "\n",
    "# 生成查询的嵌入向量\n",
    "result = embedding_model.embed_query(\"查询向量示例\")\n",
    "\n",
    "# 将结果转换为 numpy 数组并打印信息\n",
    "array = np.array(result)\n",
    "print(f\"embedding shape: {array.shape}\\nembedding norm: {np.linalg.norm(array, ord=2)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FAISS数据库\n",
    "\n",
    "在代码 FAISS_REVIEWS_PATH_COSINE = \"faiss_index_cosine\" 中，\"faiss_index_cosine\" 是 FAISS 向量索引的本地存储路径，保存的是经过向量化处理后的文档索引数据。以下是详细解释：\n",
    "\n",
    "存储的具体内容\n",
    "当调用 vector_db.save_local(FAISS_REVIEWS_PATH_COSINE) 时，会在该路径下生成以下文件：\n",
    "\n",
    "index.faiss\n",
    "二进制文件，存储向量索引的核心数据（包括向量数据、索引结构等）。\n",
    "\n",
    "index.pkl（可选）\n",
    "存储元数据（如文档的原始文本、ID等，需通过 LangChain 额外配置）。\n",
    "\n",
    "这些文件共同构成一个完整的可复用的向量数据库。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FAISS_REVIEWS_PATH_COSINE = \"faiss_index_cosine\" # 向量库存储路径\n",
    "FAISS_INDEX_NAME = \"index\" # 向量库索引名称\n",
    "FAISS_DISTANCE_STRATEGY_COSINE = \"COSINE_DISTANCE\" # 向量库距离计算策略\n",
    "\n",
    "# 用于根据csv数据生成向量库的函数。documents就是前面csv数据的导入结果。embedding_model就是上面定义的嵌入模型。\n",
    "def get_vector_database(documents, embedding_model, distance_strategy):\n",
    "\n",
    "  vector_database = FAISS.from_documents(\n",
    "      documents, embedding_model,\n",
    "      distance_strategy= distance_strategy\n",
    "      )\n",
    "  return vector_database\n",
    "\n",
    "# 嵌入向量库。分批次处理文档，加入了等待时间，避免API限制（现在的版本是把向量库保存在本地，没有对应限制）。\n",
    "import time\n",
    "doclen = len(documents) # 这里的长度指的是前面读的数据的行数。\n",
    "for batch in range(doclen//100 + 1): # 将每个店铺的信息独立转换为一个向量，且每次并行处理 100 个店铺的向量\n",
    "    docs = documents[batch*100:(batch+1)*100]\n",
    "    if batch == 0:\n",
    "        vector_db = get_vector_database(docs, embedding_model, FAISS_DISTANCE_STRATEGY_COSINE)\n",
    "    else:\n",
    "        vector_db.merge_from(get_vector_database(docs, embedding_model, FAISS_DISTANCE_STRATEGY_COSINE))\n",
    "    time.sleep(10) # 每次处理完100条数据，休眠10秒，防止api限制。\n",
    "    \n",
    "#储存并加载向量库\n",
    "vector_db.save_local(folder_path=FAISS_REVIEWS_PATH_COSINE, index_name=FAISS_INDEX_NAME)\n",
    "vector_db = FAISS.load_local(folder_path=FAISS_REVIEWS_PATH_COSINE,\n",
    "                             embeddings=embedding_model,\n",
    "                             index_name=FAISS_INDEX_NAME,\n",
    "                             allow_dangerous_deserialization=True) # 允许反序列化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 验证效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='name=箪食记(汉口路店)\n",
      "address=汉口路75-2号\n",
      "location=118.777185,32.053960\n",
      "type=餐饮服务;中餐厅;中餐厅\n",
      "cost=31.0\n",
      "rating=4.2\n",
      "opentime_week=周一至周六 09:00-20:00\n",
      "tel=13951883009;15651837225' metadata={'location': '118.777185,32.053960', 'opentime_week': '周一至周六 09:00-20:00'}\n",
      "\n",
      "page_content='name=膳当家黄焖鸡米饭(汉口路店)\n",
      "address=汉口路38号\n",
      "location=118.778647,32.053664\n",
      "type=餐饮服务;中餐厅;中餐厅\n",
      "tag=鸡肉\n",
      "cost=19.0\n",
      "rating=4.4\n",
      "opentime_today=09:00-21:00\n",
      "opentime_week=周一至周日 09:00-21:00\n",
      "tel=13851644907;15305150776' metadata={'location': '118.778647,32.053664', 'opentime_week': '周一至周日 09:00-21:00'}\n",
      "\n",
      "page_content='name=沙县小吃(汉口路店)\n",
      "address=汉口路73号\n",
      "location=118.778214,32.053989\n",
      "type=餐饮服务;中餐厅;特色/地方风味餐厅\n",
      "cost=13.0\n",
      "rating=4.4\n",
      "opentime_today=10:00-21:00\n",
      "opentime_week=周一至周日 10:00-21:00\n",
      "tel=18752023233;19941534156' metadata={'location': '118.778214,32.053989', 'opentime_week': '周一至周日 10:00-21:00'}\n",
      "\n",
      "page_content='name=鱼塘鲜专业鱼馆(汉口路店)\n",
      "address=华侨路街道汉口路32号\n",
      "location=118.778987,32.053660\n",
      "type=餐饮服务;中餐厅;海鲜酒楼\n",
      "cost=66.0\n",
      "rating=4.4\n",
      "opentime_today=09:00-21:30\n",
      "opentime_week=周一至周日 09:00-21:30\n",
      "tel=18951000166' metadata={'location': '118.778987,32.053660', 'opentime_week': '周一至周日 09:00-21:30'}\n",
      "\n",
      "page_content='name=荆州锅盔(汉口路小区店)\n",
      "address=汉口路47号汉口路小区\n",
      "location=118.779209,32.053463\n",
      "type=餐饮服务;餐饮相关场所;餐饮相关\n",
      "cost=5.0\n",
      "rating=4.4\n",
      "tel=13182947373;18651699663' metadata={'location': '118.779209,32.053463', 'opentime_week': nan}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "docs = vector_db.similarity_search(\"馄饨，汉口路\", k = 5)\n",
    "for doc in docs:\n",
    "    print(doc, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='name=台式烩饭(金银街小区店)\n",
      "address=上海路158号1栋2单元\n",
      "location=118.774736,32.057582\n",
      "type=餐饮服务;中餐厅;台湾菜\n",
      "cost=17.0\n",
      "rating=4.4\n",
      "opentime_today=09:00-22:00\n",
      "opentime_week=周一至周日 09:00-22:00\n",
      "tel=025-83308211' metadata={'location': '118.774736,32.057582', 'opentime_week': '周一至周日 09:00-22:00'}\n",
      "\n",
      "page_content='name=鱼你在一起(恒基中心公寓店)\n",
      "address=丹凤街29号大润发一层\n",
      "location=118.786668,32.054497\n",
      "type=餐饮服务;餐饮相关场所;餐饮相关\n",
      "rating=4.2\n",
      "opentime_today=09:00-21:00\n",
      "opentime_week=周一至周日 09:00-21:00\n",
      "tel=13770909712' metadata={'location': '118.786668,32.054497', 'opentime_week': '周一至周日 09:00-21:00'}\n",
      "\n",
      "page_content='name=陕老顺肉夹馍\n",
      "address=汉口路30号\n",
      "location=118.779105,32.053716\n",
      "type=餐饮服务;餐饮相关场所;餐饮相关\n",
      "tag=肉夹馍\n",
      "rating=4.4\n",
      "opentime_today=10:00-21:00\n",
      "opentime_week=周一至周日 10:00-21:00\n",
      "tel=15924140124' metadata={'location': '118.779105,32.053716', 'opentime_week': '周一至周日 10:00-21:00'}\n",
      "\n",
      "page_content='name=美鸽记·中山石岐乳鸽\n",
      "address=青岛路33-3号\n",
      "location=118.778138,32.052878\n",
      "type=餐饮服务;中餐厅;中餐厅\n",
      "tag=红米肠\n",
      "rating=4.6\n",
      "opentime_today=10:00-14:00 16:00-22:00\n",
      "opentime_week=周一至周日 10:00-14:00，16:00-22:00\n",
      "tel=18752079369' metadata={'location': '118.778138,32.052878', 'opentime_week': '周一至周日 10:00-14:00，16:00-22:00'}\n",
      "\n",
      "page_content='name=福桔家庭厨房\n",
      "address=汉口路42号\n",
      "location=118.778479,32.053663\n",
      "type=餐饮服务;中餐厅;中餐厅\n",
      "tag=寿喜锅,糖醋排骨\n",
      "rating=4.7\n",
      "opentime_today=11:00-13:30 17:00-20:30\n",
      "opentime_week=周日 11:00-14:30,17:00-20:30；周六 11:00-20:30；周一至周五 11:00-13:30,17:00-20:30\n",
      "tel=19961882001' metadata={'location': '118.778479,32.053663', 'opentime_week': '周日 11:00-14:30,17:00-20:30；周六 11:00-20:30；周一至周五 11:00-13:30,17:00-20:30'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "docs = vector_db.similarity_search(\"披萨\", k = 5)\n",
    "for doc in docs:\n",
    "    print(doc, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入大语言模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AuthenticationError",
     "evalue": "Error code: 401 - {'error': {'message': 'Incorrect API key provided: p. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAuthenticationError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmessages\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HumanMessage, SystemMessage, AIMessage\n\u001b[32m     16\u001b[39m messages = [\n\u001b[32m     17\u001b[39m     SystemMessage(\u001b[33m\"\u001b[39m\u001b[33mTranslate the following from English into French\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     18\u001b[39m     HumanMessage(\u001b[33m\"\u001b[39m\u001b[33mhi!\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     19\u001b[39m ]\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[43mllm\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Chrom\\.conda\\envs\\ByteBites\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:369\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    357\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    358\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    359\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    364\u001b[39m     **kwargs: Any,\n\u001b[32m    365\u001b[39m ) -> BaseMessage:\n\u001b[32m    366\u001b[39m     config = ensure_config(config)\n\u001b[32m    367\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    368\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m369\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    370\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    371\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    374\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    375\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    376\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    379\u001b[39m     ).message\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Chrom\\.conda\\envs\\ByteBites\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:946\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    937\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    938\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    939\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    943\u001b[39m     **kwargs: Any,\n\u001b[32m    944\u001b[39m ) -> LLMResult:\n\u001b[32m    945\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m946\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Chrom\\.conda\\envs\\ByteBites\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:765\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    762\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    763\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    764\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m765\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    766\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    767\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    768\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    769\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    770\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    771\u001b[39m         )\n\u001b[32m    772\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    773\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Chrom\\.conda\\envs\\ByteBites\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1011\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1009\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1010\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1011\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1014\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1015\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Chrom\\.conda\\envs\\ByteBites\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:957\u001b[39m, in \u001b[36mBaseChatOpenAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    955\u001b[39m     generation_info = {\u001b[33m\"\u001b[39m\u001b[33mheaders\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(raw_response.headers)}\n\u001b[32m    956\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m957\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._create_chat_result(response, generation_info)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Chrom\\.conda\\envs\\ByteBites\\Lib\\site-packages\\openai\\_utils\\_utils.py:287\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    285\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    286\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m287\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Chrom\\.conda\\envs\\ByteBites\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py:925\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    882\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    883\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    884\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    922\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m    923\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m    924\u001b[39m     validate_response_format(response_format)\n\u001b[32m--> \u001b[39m\u001b[32m925\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    926\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    927\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    929\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    933\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    934\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    936\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    937\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    938\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    939\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    940\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    941\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    942\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    947\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    948\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    949\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    951\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    954\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    955\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    956\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    959\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    960\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    961\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[32m    962\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m    963\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    964\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    965\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    966\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    967\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    968\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    969\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    970\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Chrom\\.conda\\envs\\ByteBites\\Lib\\site-packages\\openai\\_base_client.py:1239\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1225\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1226\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1227\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1234\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1235\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1236\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1237\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1238\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1239\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Chrom\\.conda\\envs\\ByteBites\\Lib\\site-packages\\openai\\_base_client.py:1034\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1031\u001b[39m             err.response.read()\n\u001b[32m   1033\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1034\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1036\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1038\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mAuthenticationError\u001b[39m: Error code: 401 - {'error': {'message': 'Incorrect API key provided: p. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_community.llms import HuggingFaceHub\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "import getpass\n",
    "\n",
    "# 加载环境变量（包括模型配置）\n",
    "load_dotenv()\n",
    "\n",
    "# ========== 可配置部分（支持环境变量或直接修改此处）==========\n",
    "client = OpenAI(\n",
    "  api_key=os.getenv(\"QWEN_API_KEY\"),\n",
    "  base_url=os.getenv(\"QWEN_BASE_URL\")\n",
    ")\n",
    "MODEL = os.getenv(\"QWEN_MODEL_NAME\") # qwen2.5-14b-instruct-1m\n",
    "MODEL_CONFIG = {\n",
    "    \"provider\": os.getenv(\"MODEL_PROVIDER\", \"openai\"),  # 可选：openai / huggingface / local\n",
    "    \"model_name\": os.getenv(\"MODEL_NAME\", \"gpt-4o\"),     # 模型名称\n",
    "    \"api_key\": os.getenv(\"API_KEY\", \"\"),                 # 各平台的API Key\n",
    "    \"local_model_path\": os.getenv(\"LOCAL_MODEL_PATH\", \"\")# 本地模型路径（如果 provider=local）\n",
    "}\n",
    "# =====================================================\n",
    "\n",
    "def init_llm(config: dict) -> object:\n",
    "    \"\"\"根据配置初始化大模型\"\"\"\n",
    "    provider = config[\"provider\"].lower()\n",
    "    \n",
    "    if provider == \"openai\":\n",
    "        if not config[\"api_key\"]:\n",
    "            config[\"api_key\"] = getpass.getpass(\"Enter OpenAI API Key: \")\n",
    "        return ChatOpenAI(\n",
    "            model=config[\"model_name\"],\n",
    "            openai_api_key=config[\"api_key\"]\n",
    "        )\n",
    "    elif provider == \"huggingface\":\n",
    "        if not config[\"api_key\"]:\n",
    "            config[\"api_key\"] = getpass.getpass(\"Enter HuggingFace Hub Token: \")\n",
    "        return HuggingFaceHub(\n",
    "            repo_id=config[\"model_name\"],\n",
    "            huggingfacehub_api_token=config[\"api_key\"]\n",
    "        )\n",
    "    elif provider == \"local\":\n",
    "        from langchain_community.llms import LlamaCpp  # 示例：本地运行 Llama\n",
    "        return LlamaCpp(\n",
    "            model_path=config[\"local_model_path\"],\n",
    "            temperature=0.5\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"不支持的模型提供商: {provider}\")\n",
    "\n",
    "# 初始化模型\n",
    "llm = init_llm(MODEL_CONFIG)\n",
    "\n",
    "# 测试调用\n",
    "messages = [\n",
    "    SystemMessage(\"Translate the following from English into French\"),\n",
    "    HumanMessage(\"hi!\"),\n",
    "]\n",
    "response = llm.invoke(messages)\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangChain pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import (\n",
    "    PromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    ChatPromptTemplate,)\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.schema.runnable import RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_template_str = \"\"\"\n",
    "你的工作是使用高德地图上的餐馆和酒吧评论来帮助人们找到吃饭或喝酒的最佳地点。\n",
    "使用以下信息和评论回答问题。如果上下文不是关于餐馆的，\n",
    "然后请告诉用户，您只能提供帮助并回答与餐厅相关的问题。\n",
    "如果你根据上下文不知道答案，就说你不知道。答案上下文\n",
    "{context}\n",
    "\"\"\"\n",
    "\n",
    "system_prompt = SystemMessagePromptTemplate(\n",
    "    prompt=PromptTemplate(\n",
    "        input_variables=[\"context\"], template=review_template_str\n",
    "    )\n",
    ")\n",
    "\n",
    "human_prompt = HumanMessagePromptTemplate(\n",
    "    prompt=PromptTemplate(input_variables=[\"question\"], template=\"{question}\")\n",
    ")\n",
    "messages = [system_prompt, human_prompt]\n",
    "\n",
    "review_prompt_template = ChatPromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"], messages=messages\n",
    ")\n",
    "\n",
    "reviews_retriever = vector_db.as_retriever(search_kwargs={'k': 20,})\n",
    "\n",
    "review_chain = (\n",
    "    {\"context\": reviews_retriever, \"question\": RunnablePassthrough()}\n",
    "    | review_prompt_template\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 案例应用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在汉口路，您可以尝试以下餐馆，提供四川菜和面食：\n",
      "\n",
      "1. **四川宜宾燃面**\n",
      "   - 地址：汉口路48号\n",
      "   - 评分：4.7\n",
      "   - 营业时间：周一至周日 09:00-20:30\n",
      "   - 电话：13072527682; 17326125923\n",
      "\n",
      "2. **兰州拉面刀削面(汉口路店)**\n",
      "   - 地址：汉口路36号\n",
      "   - 评分：4.5\n",
      "   - 营业时间：周一至周日 09:00-21:00\n",
      "   - 电话：17327791285\n",
      "\n",
      "3. **西安特色面馆(汉口路店)**\n",
      "   - 地址：汉口路47号01幢一楼\n",
      "   - 评分：4.0\n",
      "   - 营业时间：每天 07:20-21:30\n",
      "   - 电话：18114808698\n",
      "\n",
      "这些地方都可以尝到美味的四川面。希望您能享用美食！\n"
     ]
    }
   ],
   "source": [
    "question = \"\"\"汉口路哪里可以吃到四川的面\"\"\"\n",
    "print(review_chain.invoke(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你可以去以下两个肯德基：\n",
      "\n",
      "1. **肯德基(珠江路地铁店)**\n",
      "   - 地址：中山路221号负一层101至106室115至119室\n",
      "   - 营业时间：周一至周日 06:00-21:00\n",
      "   - 电话：025-85601286\n",
      "   - 评分：4.3\n",
      "   - 费用：约21元\n",
      "\n",
      "2. **肯德基(学府店)**\n",
      "   - 地址：丹凤街39号金润发购物中心1层\n",
      "   - 营业时间：周一至周日 10:00-23:00\n",
      "   - 电话：025-83222982\n",
      "   - 评分：4.8\n",
      "   - 费用：约44元\n",
      "\n",
      "3. **肯德基(广州店)**\n",
      "   - 地址：广州路104号\n",
      "   - 营业时间：24小时营业\n",
      "   - 电话：025-86632902\n",
      "   - 评分：4.6\n",
      "   - 费用：约41元\n",
      "\n",
      "你可以根据自己的位置和时间选择最合适的肯德基。\n"
     ]
    }
   ],
   "source": [
    "question = \"\"\"我想吃肯德基\"\"\"\n",
    "print(review_chain.invoke(question))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ByteBites",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
