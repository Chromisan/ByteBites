{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# é…ç½®ç¯å¢ƒ\n",
    "\n",
    "åœ¨è¿è¡Œä¹‹å‰éœ€è¦å®‰è£…æ‰€éœ€çš„pythonåŒ…ã€‚å»ºè®®ä½¿ç”¨anacondaåˆ›å»ºä¸€ä¸ªæ–°çš„è™šæ‹Ÿç¯å¢ƒï¼Œå…·ä½“æ–¹æ³•ä¸ºæ‰“å¼€Anaconda navigatorï¼Œåˆ›å»ºç¯å¢ƒï¼Œç¯å¢ƒåç§°å¯ä»¥å‘½åä¸ºByteBitesã€‚\n",
    "\n",
    "æ¿€æ´»ç¯å¢ƒï¼Œç¡®ä¿åœ¨vscodeçš„èµ„æºç®¡ç†å™¨ä¸­æ‰“å¼€ByteBitesæ–‡ä»¶å¤¹ã€‚åœ¨vscodeçš„å·¦ä¾§pythonæ‰©å±•ä¸­ï¼Œåœ¨global environmentsï¼Œé€‰ä¸­åˆšæ‰å®‰è£…çš„ç¯å¢ƒï¼Œç‚¹å‡»open in terminalï¼Œåœ¨æ‰“å¼€çš„å‘½ä»¤è¡Œä¸­è¾“å…¥ä»¥ä¸‹å‘½ä»¤å®‰è£…æ‰€éœ€çš„åŒ…ï¼š\n",
    "```bash\n",
    "pip install -r italy/requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain.prompts import (\n",
    "    PromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    ChatPromptTemplate,)\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain_community.document_loaders.dataframe import DataFrameLoader\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain.embeddings import CacheBackedEmbeddings\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "\n",
    "DATASET_PATH = \"..\\\\Amap-results_NJU-Gulou-3000m.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# å¯¼å…¥CSVæ•°æ®åº“\n",
    "\n",
    "ä»¥ä¸‹ä»£ç ä»CSVæ–‡ä»¶å¯¼å…¥é¤å…æ•°æ®ï¼Œå¹¶ç”Ÿæˆä¸€ä¸ªæ–°çš„æ–‡æ¡£å¯¹è±¡documentsã€‚è¿™ä¸ªåŠŸèƒ½ç”±DataFrameLoaderæä¾›ã€‚\n",
    "\n",
    "### æ•°æ®ç»“æ„è¯´æ˜\n",
    "\n",
    "documentså¯ä»¥ç†è§£ä¸ºä¸€ä¸ªlistè¡¨æ ¼ï¼Œæ¯ä¸€è¡Œæ˜¯åŒ…å«ä¸¤ä¸ªå­—æ®µçš„dictï¼Œä¸¤ä¸ªå­—æ®µåˆ†åˆ«ä¸ºï¼š  \n",
    "- `page_content`ï¼šå€¼ä¸ºå­—ç¬¦ä¸²ã€‚å°†é¤å…çš„æ‰€æœ‰ä¿¡æ¯æ•´åˆåœ¨ä¸€ä¸ªå­—ç¬¦ä¸²ä¸­ï¼Œç”¨äºå–‚ç»™å¤§æ¨¡å‹ã€‚\n",
    "- `metadata`ï¼šå€¼ä¸ºdictã€‚å‚¨å­˜å‡†å¤‡ç”¨äºåˆè¿‡æ»¤çš„ç¡¬æ€§æŒ‡æ ‡å€¼ï¼Œå¦‚ç»çº¬åº¦ã€è¥ä¸šæ—¶é—´ç­‰ã€‚ \n",
    "\n",
    "### ç¤ºä¾‹\n",
    "\n",
    "å‡è®¾åŸå§‹csvæ–‡ä»¶å¦‚ä¸‹ï¼š\n",
    "```csv\n",
    "name,address,location,type,tel,cost,rating,opentime_today,opentime_week,tag\n",
    "å·´èœ€é±¼èŠ±(å—å¤§åº—),æ¹–å—è·¯è¡—é“æ±‰å£è·¯30å·,\"118.779220,32.053685\",é¤é¥®æœåŠ¡;ä¸­é¤å…;ç«é”…åº—,15380870767,,4.4,09:00-21:00,å‘¨ä¸€è‡³å‘¨æ—¥ 09:00-21:00,\n",
    "é™•è€é¡ºè‚‰å¤¹é¦,æ±‰å£è·¯30å·,\"118.779105,32.053716\",é¤é¥®æœåŠ¡;é¤é¥®ç›¸å…³åœºæ‰€;é¤é¥®ç›¸å…³,15924140124,,4.4,10:00-21:00,å‘¨ä¸€è‡³å‘¨æ—¥ 10:00-21:00,è‚‰å¤¹é¦\n",
    "```\n",
    "\n",
    "å¯¼å…¥åçš„ç»“æœä¸ºï¼š\n",
    "```python\n",
    "documents = [\n",
    "    ..., # ç¬¬ä¸€è¡Œç•¥\n",
    "    {\n",
    "        \"page_content\": \"name=é™•è€é¡ºè‚‰å¤¹é¦\\naddress=æ±‰å£è·¯30å·\\nlocation=118.779105,32.053716\\ntype=é¤é¥®æœåŠ¡;é¤é¥®ç›¸å…³åœºæ‰€;é¤é¥®ç›¸å…³\\ntag=è‚‰å¤¹é¦\\nrating=4.4\\nopentime_today=10:00-21:00\\nopentime_week=å‘¨ä¸€è‡³å‘¨æ—¥ 10:00-21:00\\ntel=15924140124\",\n",
    "        \"metadata\": {\n",
    "            \"location\": \"118.779105,32.053716\",\n",
    "            \"opentime_week\": \"å‘¨ä¸€è‡³å‘¨æ—¥ 10:00-21:00\"\n",
    "        }\n",
    "    }\n",
    "]\n",
    "```\n",
    "\n",
    "### **æ³¨æ„**\n",
    "\n",
    "- è¯»å–åº—é“ºæ•°æ®çš„ä»£ç æ›´æ”¹ï¼Œå¯¼è‡´csvæ–‡ä»¶ä¸­å­—æ®µå‘ç”Ÿå˜åŒ–æ—¶ï¼šdef content_func ä¸­ python content_fields çš„å€¼è¦éšä¹‹æ›´æ”¹ã€‚\n",
    "- æƒ³ä½œä¸ºç¡¬æ€§æŒ‡æ ‡çš„å­—æ®µå‘ç”Ÿå˜åŒ–æ—¶ï¼šè°ƒç”¨éƒ¨åˆ† metadata_fields ä¸­çš„å€¼è¦æ›´æ”¹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name=é™•è€é¡ºè‚‰å¤¹é¦\n",
      "address=æ±‰å£è·¯30å·\n",
      "type=é¤é¥®æœåŠ¡;é¤é¥®ç›¸å…³åœºæ‰€;é¤é¥®ç›¸å…³\n",
      "tag=è‚‰å¤¹é¦\n",
      "rating=4.4\n",
      "opentime_today=10:00-21:00\n",
      "opentime_week=å‘¨ä¸€è‡³å‘¨æ—¥ 10:00-21:00\n",
      "{'location': '118.779105,32.053716', 'opentime_week': 'å‘¨ä¸€è‡³å‘¨æ—¥ 10:00-21:00'}\n"
     ]
    }
   ],
   "source": [
    "def get_documents(content_func=lambda row: row['name'] + '\\n' + row['tag'],  # ç”¨äºå¯¼å…¥page_contentçš„å‡½æ•°ã€‚å¦‚æœè°ƒç”¨æ—¶æ²¡ä¼ è¿™ä¸ªå‚æ•°ï¼Œé»˜è®¤æ˜¯å°†æ¯ä¸€è¡Œçš„nameå’Œtagæ‹¼æ¥èµ·æ¥ã€‚\n",
    "                  # source_func=lambda row: row['address'],  # åé¢æ²¡ç”¨åˆ°è¿™ä¸ªå‡½æ•°ã€‚ç”¨äºå¯¼å…¥sourceçš„å‡½æ•°ã€‚é»˜è®¤æ˜¯å°†addressä½œä¸ºæ–‡æ¡£æ¥æºã€‚\n",
    "                  metadata_fields=[]):  # å¯¼å…¥metadataï¼ˆä¸€ä¸ªdictï¼‰æ—¶æ‰“ç®—åŠ å…¥è¿›å»çš„å­—æ®µåˆ—è¡¨ï¼Œé»˜è®¤ä¸ºç©ºã€‚\n",
    "\n",
    "    # åŠ è½½æ•°æ®åº“ï¼Œè¯»å–æŒ‡å®šè·¯å¾„çš„ CSV æ–‡ä»¶\n",
    "    dataset_df = pd.read_csv(DATASET_PATH)\n",
    "    dataset_df.drop_duplicates(inplace=True) # åˆ é™¤é‡å¤æ•°æ®ï¼Œç¡®ä¿æ•°æ®å”¯ä¸€æ€§\n",
    "\n",
    "    # å¯¹åŸæœ‰æ•°æ®åˆ†åˆ«ç”¨å‡½æ•°content_funcå’Œsource_funcå¤„ç†ï¼Œæ·»åŠ æ–°çš„åˆ— 'page_content' å’Œ'source'ï¼Œè¿™ä¸¤åˆ—çš„å€¼ç”±ä¸¤ä¸ªå‡½æ•°å¾—åˆ°\n",
    "    dataset_df['page_content'] = dataset_df.apply(content_func, axis=1)\n",
    "    # dataset_df['source'] = dataset_df.apply(source_func, axis=1)\n",
    "\n",
    "    # å°† 'page_content' å­—æ®µæ·»åŠ åˆ°metadata_fieldsä¸­\n",
    "    metadata_fields = list(set(metadata_fields + ['page_content']))\n",
    "\n",
    "    # ä½¿ç”¨ DataFrameLoader ç”Ÿæˆä¸€ä¸ªæ–°æ–‡æ¡£å¯¹è±¡ã€‚ 'page_content'åˆ—ä½œä¸ºæ–‡æ¡£å†…å®¹ï¼Œå…¶ä»–æ‰€æœ‰åˆ—éƒ½ä½œä¸ºmetadataçš„å†…å®¹\n",
    "    loader = DataFrameLoader(dataset_df[metadata_fields], page_content_column='page_content')\n",
    "    return loader.load()\n",
    "\n",
    "def content_func(row) -> str: # å®šä¹‰content_funcå‡½æ•°ï¼Œç”¨äºæŠŠæ¯å®¶åº—çš„æ‰€æœ‰ä¿¡æ¯æ‹¼åˆ°ä¸€èµ·ï¼Œè¿”å›æˆä¸€ä¸ªå­—ç¬¦ä¸²ã€‚ä¸­é—´ç”¨æ¢è¡Œç¬¦éš”å¼€ã€‚\n",
    "  content_fields = [\"name\",\n",
    "                    \"address\",\n",
    "                    # \"location\", \n",
    "                    \"type\",\n",
    "                    \"tag\",\n",
    "                    \"cost\",\n",
    "                    \"rating\",\n",
    "                    \"opentime_today\",\n",
    "                    \"opentime_week\", \n",
    "                    # \"tel\"\n",
    "                    ]\n",
    "  return '\\n'.join(f\"{key}={row[key]}\" for key in content_fields if pd.notna(row[key]))\n",
    "\n",
    "# è°ƒç”¨\n",
    "metadata_fields = [\"location\", \"opentime_week\"]\n",
    "documents = get_documents(content_func, metadata_fields=metadata_fields)\n",
    "\n",
    "# å±•ç¤º\n",
    "print(documents[1].page_content)\n",
    "print(documents[1].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dotenv import load_dotenv\n",
    "# from langchain_openai import OpenAIEmbeddings\n",
    "# import os\n",
    "\n",
    "# #åŠ è½½ç¯å¢ƒå˜é‡\n",
    "# load_dotenv()\n",
    "# #é…ç½®åµŒå…¥æ¨¡å‹\n",
    "# EMBEDDING_MODEL_NAME = \"text-embedding-3-small\"  \n",
    "# embedding_model = OpenAIEmbeddings(\n",
    "#     model=EMBEDDING_MODEL_NAME,\n",
    "#     openai_api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# é…ç½®åµŒå…¥vecterbaseæ‰€ç”¨çš„æ¨¡å‹\n",
    "\n",
    "ç”¨çš„æ˜¯huggingfaceä¸Šé¢çš„æŸä¸ªè½»é‡çº§å¼€æºæ¨¡å‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain_huggingface'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_huggingface\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01membeddings\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HuggingFaceEmbeddings\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'langchain_huggingface'"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# åˆå§‹åŒ– HuggingFaceEmbeddings æ¨¡å‹\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",  # è½»é‡çº§æ¨¡å‹\n",
    "    model_kwargs={\"device\": \"cpu\"},  # å¦‚æœç”µè„‘ä¸Šå®‰è£…äº†è‹±ä¼Ÿè¾¾æ˜¾å¡ï¼Œå¯æ”¹æˆ \"cuda\" æ¥åŠ é€Ÿ\n",
    "    encode_kwargs={\"normalize_embeddings\": True})  # å½’ä¸€åŒ–\n",
    "\n",
    "# ç”ŸæˆæŸ¥è¯¢çš„åµŒå…¥å‘é‡\n",
    "result = embedding_model.embed_query(\"æŸ¥è¯¢å‘é‡ç¤ºä¾‹\")\n",
    "\n",
    "# å°†ç»“æœè½¬æ¢ä¸º numpy æ•°ç»„å¹¶æ‰“å°ä¿¡æ¯\n",
    "array = np.array(result)\n",
    "print(f\"embedding shape: {array.shape}\\nembedding norm: {np.linalg.norm(array, ord=2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FAISSæ•°æ®åº“\n",
    "\n",
    "åœ¨ä»£ç  FAISS_REVIEWS_PATH_COSINE = \"faiss_index_cosine\" ä¸­ï¼Œ\"faiss_index_cosine\" æ˜¯ FAISS å‘é‡ç´¢å¼•çš„æœ¬åœ°å­˜å‚¨è·¯å¾„ï¼Œä¿å­˜çš„æ˜¯ç»è¿‡å‘é‡åŒ–å¤„ç†åçš„æ–‡æ¡£ç´¢å¼•æ•°æ®ã€‚ä»¥ä¸‹æ˜¯è¯¦ç»†è§£é‡Šï¼š\n",
    "\n",
    "å­˜å‚¨çš„å…·ä½“å†…å®¹\n",
    "å½“è°ƒç”¨ vector_db.save_local(FAISS_REVIEWS_PATH_COSINE) æ—¶ï¼Œä¼šåœ¨è¯¥è·¯å¾„ä¸‹ç”Ÿæˆä»¥ä¸‹æ–‡ä»¶ï¼š\n",
    "\n",
    "index.faiss\n",
    "äºŒè¿›åˆ¶æ–‡ä»¶ï¼Œå­˜å‚¨å‘é‡ç´¢å¼•çš„æ ¸å¿ƒæ•°æ®ï¼ˆåŒ…æ‹¬å‘é‡æ•°æ®ã€ç´¢å¼•ç»“æ„ç­‰ï¼‰ã€‚\n",
    "\n",
    "index.pklï¼ˆå¯é€‰ï¼‰\n",
    "å­˜å‚¨å…ƒæ•°æ®ï¼ˆå¦‚æ–‡æ¡£çš„åŸå§‹æ–‡æœ¬ã€IDç­‰ï¼Œéœ€é€šè¿‡ LangChain é¢å¤–é…ç½®ï¼‰ã€‚\n",
    "\n",
    "è¿™äº›æ–‡ä»¶å…±åŒæ„æˆä¸€ä¸ªå®Œæ•´çš„å¯å¤ç”¨çš„å‘é‡æ•°æ®åº“ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "FAISS_REVIEWS_PATH_COSINE = \"faiss_index_cosine\" # å‘é‡åº“å­˜å‚¨è·¯å¾„\n",
    "FAISS_INDEX_NAME = \"index\" # å‘é‡åº“ç´¢å¼•åç§°\n",
    "FAISS_DISTANCE_STRATEGY_COSINE = \"COSINE_DISTANCE\" # å‘é‡åº“è·ç¦»è®¡ç®—ç­–ç•¥\n",
    "\n",
    "# ç”¨äºæ ¹æ®csvæ•°æ®ç”Ÿæˆå‘é‡åº“çš„å‡½æ•°ã€‚documentså°±æ˜¯å‰é¢csvæ•°æ®çš„å¯¼å…¥ç»“æœã€‚embedding_modelå°±æ˜¯ä¸Šé¢å®šä¹‰çš„åµŒå…¥æ¨¡å‹ã€‚\n",
    "def get_vector_database(documents, embedding_model, distance_strategy):\n",
    "\n",
    "  vector_database = FAISS.from_documents(\n",
    "      documents, embedding_model,\n",
    "      distance_strategy= distance_strategy\n",
    "      )\n",
    "  return vector_database\n",
    "\n",
    "# åµŒå…¥å‘é‡åº“ã€‚åˆ†æ‰¹æ¬¡å¤„ç†æ–‡æ¡£ï¼ŒåŠ å…¥äº†ç­‰å¾…æ—¶é—´ï¼Œé¿å…APIé™åˆ¶ï¼ˆç°åœ¨çš„ç‰ˆæœ¬æ˜¯æŠŠå‘é‡åº“ä¿å­˜åœ¨æœ¬åœ°ï¼Œæ²¡æœ‰å¯¹åº”é™åˆ¶ï¼‰ã€‚\n",
    "import time\n",
    "doclen = len(documents) # è¿™é‡Œçš„é•¿åº¦æŒ‡çš„æ˜¯å‰é¢è¯»çš„æ•°æ®çš„è¡Œæ•°ã€‚\n",
    "for batch in range(doclen//100 + 1): # å°†æ¯ä¸ªåº—é“ºçš„ä¿¡æ¯ç‹¬ç«‹è½¬æ¢ä¸ºä¸€ä¸ªå‘é‡ï¼Œä¸”æ¯æ¬¡å¹¶è¡Œå¤„ç† 100 ä¸ªåº—é“ºçš„å‘é‡\n",
    "    docs = documents[batch*100:(batch+1)*100]\n",
    "    if batch == 0:\n",
    "        vector_db = get_vector_database(docs, embedding_model, FAISS_DISTANCE_STRATEGY_COSINE)\n",
    "    else:\n",
    "        vector_db.merge_from(get_vector_database(docs, embedding_model, FAISS_DISTANCE_STRATEGY_COSINE))\n",
    "    time.sleep(10) # æ¯æ¬¡å¤„ç†å®Œ100æ¡æ•°æ®ï¼Œä¼‘çœ 10ç§’ï¼Œé˜²æ­¢apié™åˆ¶ã€‚\n",
    "    \n",
    "#å‚¨å­˜å¹¶åŠ è½½å‘é‡åº“\n",
    "vector_db.save_local(folder_path=FAISS_REVIEWS_PATH_COSINE, index_name=FAISS_INDEX_NAME)\n",
    "vector_db = FAISS.load_local(folder_path=FAISS_REVIEWS_PATH_COSINE,\n",
    "                             embeddings=embedding_model,\n",
    "                             index_name=FAISS_INDEX_NAME,\n",
    "                             allow_dangerous_deserialization=True) # å…è®¸ååºåˆ—åŒ–"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### éªŒè¯æ•ˆæœ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = vector_db.similarity_search(\"é¦„é¥¨ï¼Œæ±‰å£è·¯\", k = 5)\n",
    "for doc in docs:\n",
    "    print(doc, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = vector_db.similarity_search(\"æŠ«è¨\", k = 5)\n",
    "for doc in docs:\n",
    "    print(doc, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# é…ç½®å¤§è¯­è¨€æ¨¡å‹\n",
    "éœ€è¦åœ¨ByteBitesç›®å½•ä¸‹åˆ›å»ºé…ç½®æ–‡ä»¶.envï¼Œé‡Œé¢æ·»åŠ å¤§è¯­è¨€æ¨¡å‹çš„é…ç½®ä¿¡æ¯ã€‚å¯†é’¥è¦è‡ªå·±ç”³è¯·ã€‚ä»£ç æ”¯æŒçš„æ¨¡å‹åŒ…æ‹¬ï¼šOpenAIã€Deepseekã€é€šä¹‰åƒé—®ç­‰ã€‚\n",
    "\n",
    ".envæ–‡ä»¶å½¢å¦‚ï¼š\n",
    "\n",
    "```python\n",
    "# OpenAI\n",
    "OPENAI_API_KEY = \n",
    "OPENAI_MODEL_NAME = \"gpt-4o-mini\"\n",
    "\n",
    "# Deepseek\n",
    "DEEPSEEK_API_KEY = \n",
    "DEEPSEEK_BASE_URL = 'https://api.deepseek.com'\n",
    "DEEPSEEK_MODEL_V3 = 'deepseek-chat'\n",
    "DEEPSEEK_MODEL_R1 = 'deepseek-reasoner'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response from model: content='Salut ! ğŸ˜Š' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 5, 'prompt_tokens': 12, 'total_tokens': 17, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}, 'prompt_cache_hit_tokens': 0, 'prompt_cache_miss_tokens': 12}, 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_8802369eaa_prod0425fp8', 'id': '7a2d645d-c9c7-41d3-9d32-e4dd8c79bed5', 'finish_reason': 'stop', 'logprobs': None} id='run-6ea6f5bf-f8e2-4b7f-8d84-2e22d5831ab6-0' usage_metadata={'input_tokens': 12, 'output_tokens': 5, 'total_tokens': 17, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "import getpass\n",
    "\n",
    "# åŠ è½½ç¯å¢ƒå˜é‡ï¼ˆåŒ…æ‹¬æ¨¡å‹é…ç½®ï¼‰\n",
    "load_dotenv()\n",
    "\n",
    "# ========== å¯é…ç½®éƒ¨åˆ†ï¼ˆæ”¯æŒç¯å¢ƒå˜é‡æˆ–ç›´æ¥ä¿®æ”¹æ­¤å¤„ï¼‰==========\n",
    "DEFAULT_MODEL_PROVIDER = \"deepseek\"  # é»˜è®¤æ¨¡å‹åç§°\n",
    "MODEL_PROVIDER = os.getenv(\"MODEL_PROVIDER\", DEFAULT_MODEL_PROVIDER).lower()\n",
    "# =====================================================\n",
    "\n",
    "# å®šä¹‰é…ç½®ç±»\n",
    "class ModelConfig:\n",
    "    def __init__(self, model_name, api_key, base_url=\"\", local_model_path=\"\"):\n",
    "        self.model_name = model_name\n",
    "        self.api_key = api_key\n",
    "        self.base_url = base_url\n",
    "        self.local_model_path = local_model_path\n",
    "\n",
    "# åŠ è½½æ‰€æœ‰å¯èƒ½çš„æ¨¡å‹é…ç½®\n",
    "MODEL_CONFIGS = {\n",
    "    \"openai\": ModelConfig(\n",
    "        model_name=os.getenv(\"OPENAI_MODEL_NAME\", \"gpt-4o\"),\n",
    "        api_key=os.getenv(\"OPENAI_API_KEY\", \"\"),\n",
    "        base_url=os.getenv(\"OPENAI_BASE_URL\", \"\")\n",
    "    ),\n",
    "    \"qwen\": ModelConfig(\n",
    "        model_name=os.getenv(\"QWEN_MODEL_NAME\", \"\"),\n",
    "        api_key=os.getenv(\"QWEN_API_KEY\", \"\"),\n",
    "        base_url=os.getenv(\"QWEN_BASE_URL\", \"\")\n",
    "    ),\n",
    "    \"deepseek\": ModelConfig(\n",
    "        model_name=os.getenv(\"DEEPSEEK_MODEL_NAME\", \"deepseek-chat\"),\n",
    "        api_key=os.getenv(\"DEEPSEEK_API_KEY\", \"\"),\n",
    "        base_url=os.getenv(\"DEEPSEEK_BASE_URL\", \"\")\n",
    "    )\n",
    "}\n",
    "\n",
    "# ç”¨æ¥åˆ¤æ–­æœ‰æ²¡æœ‰è¯»åˆ°å¯¹åº”çš„api keyï¼Œå¦‚æœæ²¡æœ‰ç”±ç”¨æˆ·è¾“å…¥\n",
    "def get_api_key(config: ModelConfig):\n",
    "    if not config.api_key:\n",
    "        config.api_key = getpass.getpass(\"Enter OpenAI API Key: \")\n",
    "    return config.api_key\n",
    "\n",
    "# åˆå§‹åŒ–æ¨¡å‹ï¼Œé…ç½®ç›¸å…³ä¿¡æ¯çš„å‡½æ•°\n",
    "def init_llm(model_provider: str) -> object:\n",
    "    \"\"\"æ ¹æ®é…ç½®åˆå§‹åŒ–å¤§æ¨¡å‹\"\"\"\n",
    "    config = MODEL_CONFIGS.get(model_provider)\n",
    "    if not config:\n",
    "        raise ValueError(f\"ä¸æ”¯æŒçš„æ¨¡å‹æä¾›å•†: {model_provider}\")\n",
    "    \n",
    "    api_key = get_api_key(config)\n",
    "    return ChatOpenAI(\n",
    "        model=config.model_name,\n",
    "        openai_api_key=api_key,\n",
    "        base_url=config.base_url\n",
    "        )\n",
    "    \n",
    "# åˆå§‹åŒ–æ¨¡å‹\n",
    "try:\n",
    "    llm = init_llm(MODEL_PROVIDER)\n",
    "except ValueError as e:\n",
    "    print(f\"Error initializing LLM: {e}\")\n",
    "    llm = None  # Set llm to None or handle it appropriately\n",
    "\n",
    "# æµ‹è¯•è°ƒç”¨\n",
    "messages = [\n",
    "    SystemMessage(\"Translate the following from English into French\"),\n",
    "    HumanMessage(\"hi!\"),\n",
    "]\n",
    "try:\n",
    "    response = llm.invoke(messages)\n",
    "    print(\"Response from model:\", response)\n",
    "except Exception as e:  # ä½¿ç”¨Exceptionå¯ä»¥æ•è·æ‰€æœ‰ç±»å‹çš„å¼‚å¸¸\n",
    "    print(f\"Error invoking LLM: {e}\")\n",
    "    response = None  # æˆ–è€…å…¶ä»–é€‚å½“çš„å¤„ç†æ–¹å¼"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ç”¨LangChainåŒ…è®¾ç½®å’Œå¤§æ¨¡å‹äº¤äº’çš„å·¥ä½œæµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import (\n",
    "    PromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    ChatPromptTemplate,\n",
    ")\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "\n",
    "# ========== éœ€ç¼–è¾‘éƒ¨åˆ† ==============================\n",
    "system_prompt_template = \"\"\"\n",
    "# ä½ çš„è§’è‰²\n",
    "\n",
    "ä½ æ˜¯ä¸€ä¸ªé¤å…æ¨èåŠ©æ‰‹ã€‚ä½ çš„å·¥ä½œæ˜¯ä½¿ç”¨æ•°æ®åº“ä¸­çš„é¤é¦†è¯¦ç»†ä¿¡æ¯æ¥ä¸ºç”¨æˆ·æ¨èæœ€ä½³å°±é¤åœ°ç‚¹ã€‚\n",
    "\n",
    "# è§„åˆ™\n",
    "\n",
    "ä½ åªèƒ½æ ¹æ®æ•°æ®åº“ä¸­çš„ä¿¡æ¯å›ç­”ç”¨æˆ·é—®é¢˜ã€‚\n",
    "å¦‚æœä½ å‘ç°æ•°æ®åº“ä¸­æœ‰ä¸ä¸»é¢˜æ— å…³çš„ä¿¡æ¯ï¼Œè¯·å¿½ç•¥ã€‚\n",
    "å¦‚æœä½ å‘ç°ç”¨æˆ·é—®é¢˜ä¸å°±é¤æ— å…³ï¼Œè¯·å‘Šè¯‰ç”¨æˆ·ä½ åªèƒ½å›ç­”ä¸é¤å…ç›¸å…³çš„é—®é¢˜ã€‚\n",
    "å¦‚æœä½ çœ‹äº†æ•°æ®åº“åè¿˜æ˜¯ä¸çŸ¥é“ç­”æ¡ˆï¼Œå°±è¯´ä½ ä¸çŸ¥é“ã€‚\n",
    "\n",
    "# æ•°æ®åº“çš„æ ¼å¼\n",
    "\n",
    "æ¯å®¶é¤é¦†çš„ä¿¡æ¯åŒ…æ‹¬ï¼š\n",
    "nameé¤é¦†åå­—\n",
    "addressåœ°å€\n",
    "typeé¤é¦†ç±»å‹\n",
    "tagé¤é¦†æ ‡ç­¾\n",
    "ratingç”¨æˆ·è¯„åˆ†ï¼ˆè¶Šé«˜è¶Šå¥½ï¼‰\n",
    "opentime_todayæ¯å¤©è¥ä¸šæ—¶é—´\n",
    "opentime_weekæ˜ŸæœŸå‡ è¥ä¸š\n",
    "\n",
    "# æ•°æ®åº“å†…å®¹\n",
    "\n",
    "{context}\n",
    "\"\"\"\n",
    "\n",
    "human_prompt_template = \"\"\"\n",
    "{question}\n",
    "\"\"\"\n",
    "# =====================================================\n",
    "\n",
    "# ä½¿ç”¨langchainè‡ªå¸¦çš„promptsæ¨¡æ¿ç¼–è¾‘å™¨æ¥ç¼–è¾‘promptæ ¼å¼\n",
    "system_prompt = SystemMessagePromptTemplate(\n",
    "    prompt=PromptTemplate(\n",
    "        input_variables=[\"context\"], template = system_prompt_template\n",
    "    )\n",
    ")\n",
    "human_prompt = HumanMessagePromptTemplate(\n",
    "    prompt=PromptTemplate(input_variables=[\"question\"], template = human_prompt_template)\n",
    ")\n",
    "messages = [system_prompt, human_prompt]\n",
    "total_prompt_template = ChatPromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"], messages=messages\n",
    ")\n",
    "\n",
    "# é…ç½®RAGçš„åˆæ­¥æ£€ç´¢å™¨ã€‚è¿™é‡Œæ˜¯åˆ©ç”¨ä¸Šæ–‡ä¸­é…å¥½çš„vectorbaseæ¥æ£€ç´¢å’Œç”¨æˆ·é—®é¢˜æœ€ç›¸å…³çš„å‰20æ¡é¤å…ä¿¡æ¯\n",
    "reviews_retriever = vector_db.as_retriever(search_kwargs={'k': 20,})\n",
    "\n",
    "# é…ç½®å’Œå¤§æ¨¡å‹äº¤äº’çš„å®Œæ•´chatbot\n",
    "review_chain = (\n",
    "    {\"context\": reviews_retriever, \"question\": RunnablePassthrough()}\n",
    "    | total_prompt_template\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ä½¿ç”¨ç¤ºä¾‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "åœ¨æ±‰å£è·¯é™„è¿‘ï¼Œæ‚¨å¯ä»¥å°è¯•ä»¥ä¸‹ä¸¤å®¶æä¾›å››å·é¢é£Ÿçš„é¤å…ï¼š\n",
      "\n",
      "1. **å››å·å®œå®¾ç‡ƒé¢**\n",
      "   - åœ°å€ï¼šæ±‰å£è·¯48å·\n",
      "   - ç±»å‹ï¼šå››å·èœ(å·èœ)\n",
      "   - è¯„åˆ†ï¼š4.7\n",
      "   - è¥ä¸šæ—¶é—´ï¼šå‘¨ä¸€è‡³å‘¨æ—¥ 09:00-20:30\n",
      "   - ç‰¹è‰²ï¼šæä¾›æ­£å®—çš„å®œå®¾ç‡ƒé¢ã€‚\n",
      "\n",
      "2. **ç«å±±å£å·å‘³æ’æ¡£**\n",
      "   - åœ°å€ï¼šé’å²›è·¯33-5å·ï¼ˆè·ç¦»æ±‰å£è·¯ä¸è¿œï¼‰\n",
      "   - ç±»å‹ï¼šå››å·èœ(å·èœ)\n",
      "   - è¯„åˆ†ï¼š4.7\n",
      "   - è¥ä¸šæ—¶é—´ï¼šå‘¨ä¸€è‡³å‘¨æ—¥ 11:00-22:00\n",
      "   - ç‰¹è‰²ï¼šæä¾›å¤šç§å·å‘³èœè‚´ï¼Œå¯èƒ½åŒ…æ‹¬å››å·é¢é£Ÿã€‚\n",
      "\n",
      "è¿™ä¸¤å®¶é¤å…è¯„åˆ†è¾ƒé«˜ï¼Œé€‚åˆå“å°å››å·é£å‘³çš„é¢é£Ÿã€‚\n"
     ]
    }
   ],
   "source": [
    "question = \"\"\"æ±‰å£è·¯é™„è¿‘ï¼Œå“ªé‡Œå¯ä»¥åƒåˆ°å››å·çš„é¢\"\"\"\n",
    "print(review_chain.invoke(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ ¹æ®æ•°æ®åº“ä¸­çš„ä¿¡æ¯ï¼Œä»¥ä¸‹æ˜¯å‡ å®¶è‚¯å¾·åŸºé¤å…çš„æ¨èï¼š\n",
      "\n",
      "1. **è‚¯å¾·åŸº(ç æ±Ÿè·¯åœ°é“åº—)**  \n",
      "   - åœ°å€ï¼šä¸­å±±è·¯221å·è´Ÿä¸€å±‚101è‡³106å®¤115è‡³119å®¤  \n",
      "   - è¯„åˆ†ï¼š4.3  \n",
      "   - è¥ä¸šæ—¶é—´ï¼šå‘¨ä¸€è‡³å‘¨æ—¥ 06:00-21:00  \n",
      "   - ç‰¹è‰²æ ‡ç­¾ï¼šè›‹æŒã€é¥­å›¢ã€è–¯æ¡  \n",
      "\n",
      "2. **è‚¯å¾·åŸº(å­¦åºœåº—)**  \n",
      "   - åœ°å€ï¼šä¸¹å‡¤è¡—39å·é‡‘æ¶¦å‘è´­ç‰©ä¸­å¿ƒ1å±‚  \n",
      "   - è¯„åˆ†ï¼š4.8  \n",
      "   - è¥ä¸šæ—¶é—´ï¼šå‘¨ä¸€è‡³å‘¨æ—¥ 10:00-23:00  \n",
      "   - ç‰¹è‰²æ ‡ç­¾ï¼šKFCè€åŒ—äº¬é¸¡è‚‰å·ã€è‚¯å¤§å¤§é¸¡æ’ã€é»„é‡‘é¸¡å—ã€è‘¡å¼è›‹æŒç­‰  \n",
      "\n",
      "3. **è‚¯å¾·åŸº(å¹¿å·åº—)**  \n",
      "   - åœ°å€ï¼šå¹¿å·è·¯104å·  \n",
      "   - è¯„åˆ†ï¼š4.6  \n",
      "   - è¥ä¸šæ—¶é—´ï¼š24å°æ—¶è¥ä¸š  \n",
      "   - ç‰¹è‰²æ ‡ç­¾ï¼šçº¢è±†æ´¾ã€KFCèŠ‹ç¼˜èŠ±æ·‡æ·‹ã€æµ·è‹”å²©çƒ§å¤§é¸¡è…¿é¥­ç­‰  \n",
      "\n",
      "å¦‚æœä½ éœ€è¦24å°æ—¶è¥ä¸šçš„è‚¯å¾·åŸºï¼Œå¯ä»¥é€‰æ‹©**è‚¯å¾·åŸº(å¹¿å·åº—)**ã€‚å¦‚æœä½ æƒ³è¦è¯„åˆ†è¾ƒé«˜çš„ï¼Œå¯ä»¥é€‰æ‹©**è‚¯å¾·åŸº(å­¦åºœåº—)**ã€‚\n"
     ]
    }
   ],
   "source": [
    "question = \"\"\"æˆ‘æƒ³åƒè‚¯å¾·åŸº\"\"\"\n",
    "print(review_chain.invoke(question))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ByteBites_ItalyRag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
